package com.github.javaffmpeg;

import org.bytedeco.javacpp.BytePointer;

import java.nio.ByteBuffer;
import java.util.Map;

import static org.bytedeco.javacpp.avcodec.*;
import static org.bytedeco.javacpp.avutil.*;

public class Decoder extends Coder {

	/** Convert decoded images to this pixel format. Default is BGR24. */
	private PixelFormat pixelFormat = PixelFormat.BGR24;
	
	/** Picture re-sampler that is used to decode pictures into desired picture format. */
	private PictureResampler videoResampler;
	
	/** The decoder picture format */
	private PictureFormat srcPictureFormat;
	
	/** The desired picture output format */
	private PictureFormat dstPictureFormat;
	
	private AudioFormat audioFormat;
	
	/** Decoded image structure. */
	private AVPicture picture;

	
	public Decoder(Codec codec) throws JavaFFmpegException {
		this(codec, null);
	}
	
	Decoder(Codec codec, AVCodecContext avContext) throws JavaFFmpegException {
		super(codec, avContext);
	}
	
	@Override
	public void open(Map<String, String> options) throws JavaFFmpegException {
		super.open(options);

		if (codec.getType() == MediaType.VIDEO) {
	        srcPictureFormat = new PictureFormat(avContext.width(), avContext.height(), PixelFormat.byId(avContext.pix_fmt()));
	        dstPictureFormat = new PictureFormat(avContext.width(), avContext.height(), pixelFormat);
		}
		if (codec.getType() == MediaType.AUDIO) {
			long channelLayout = avContext.channel_layout();
			int channels = avContext.channels();
			int sampleRate = avContext.sample_rate();
			int sampleFormat = avContext.sample_fmt();
			
			SampleFormat format = SampleFormat.byId(sampleFormat);
			ChannelLayout layout = ChannelLayout.byId(channelLayout);
			if (layout == null)
				layout = ChannelLayout.byChannelCount(channels);
	            
			audioFormat = new AudioFormat(format, layout, channels, sampleRate);
		}
		
		if (codec.canDecode()) {
        	// Hack to correct wrong frame rates that seem to be generated by some codecs.
            if (avContext.time_base().num() > 1000 && avContext.time_base().den() == 1) {
            	avContext.time_base().den(1000);
            }
        }
	}
	
	@Override
	public void close() {
		if (picture != null) {
			avpicture_free(picture);
			picture = null;
		}
		
		if (videoResampler != null) {
			videoResampler.close();
			videoResampler = null;
		}
		
		super.close();
	}
	
	public int getImageWidth() {
		return avContext.width();
	}
	
	public int getImageHeight() {
		return avContext.height();
	}
	
	public int getAudioChannels() {
		return avContext.channels();
	}
	
	public int getSampleRate() {
		return avContext.sample_rate();
	}
	
	public SampleFormat getSampleFormat() {
		return SampleFormat.byId(avContext.sample_fmt());
	}
	
	public PixelFormat getPixelFormat() {
		return PixelFormat.byId(avContext.pix_fmt());
	}
	
	public void setPixelFormat(PixelFormat format) {
		if (format == null)
			return;
		
		this.pixelFormat = format;
	}
	
	public AudioFrame decodeAudio(MediaPacket mediaPacket) throws JavaFFmpegException {
		if (state != State.Opened)
			throw new JavaFFmpegException("Could not decode audio, decoder is not opened.");

		if (codec.getType() != MediaType.AUDIO)
			throw new JavaFFmpegException("Could not decode audio, this is a non-audio decoder.");

		if (mediaPacket == null)
			throw new JavaFFmpegException("No audio passed to decode.");
		
		AudioFrame frame = null;
		AVPacket mPacket = mediaPacket.getAVPacket();
		
		if (mPacket != null) {
			if (av_copy_packet(avPacket, mPacket) < 0) {
				throw new JavaFFmpegException("Copy packet failed.");
			}
		}
		else {
			ByteBuffer packetData = mediaPacket.getData();
			
			if (packetData != null) {
				avPacket.data(new BytePointer(packetData));
				avPacket.size(packetData.limit());
			}
		}

	    while (avPacket.size() > 0) {
	    	// reset frame values
	    	av_frame_unref(avFrame);
		    
	        int len = avcodec_decode_audio4(avContext, avFrame, gotFrame, avPacket);
		    
	        if (len > 0) {
	        	avPacket.data(avPacket.data().position(len));
	        	avPacket.size(avPacket.size() - len);
	        }
	        
			if (len > 0 && gotFrame[0] != 0) {
				long pts = av_frame_get_best_effort_timestamp(avFrame);
				
	            int sampleFormat = avFrame.format();
	            int isPlanar = av_sample_fmt_is_planar(sampleFormat);
	            int planes = isPlanar != 0 ? avFrame.channels() : 1;
	            int bufferSize = av_samples_get_buffer_size((int[]) null, avContext.channels(), avFrame.nb_samples(), avContext.sample_fmt(), 1) / planes;
	           
				frame = new AudioFrame(audioFormat, avFrame.nb_samples());
				frame.setKeyFrame(avFrame.key_frame() != 0);
				frame.setPts(pts);
				//frame.setStreamIndex(mPacket.stream_index());
				
				for (int i = 0; i < planes; i++) {
					BytePointer pointer = avFrame.data(i).capacity(bufferSize);
					ByteBuffer buffer = pointer.asBuffer();
					buffer.position(0);
					
					frame.getPlane(i).asByteBuffer().put(buffer);
				}
			}
			else {
				break;
			}
	    }
		
		av_free_packet(avPacket);
	    
		return frame;
	}
	
	public VideoFrame decodeVideo(MediaPacket mediaPacket) throws JavaFFmpegException {
		if (state != State.Opened)
			throw new JavaFFmpegException("Could not decode video, decoder is not opened.");

		if (codec.getType() != MediaType.VIDEO)
			throw new JavaFFmpegException("Could not decode video, this is a non-video decoder.");

		if (mediaPacket == null)
			throw new JavaFFmpegException("No data passed to decode.");
		
		VideoFrame frame = new VideoFrame();
		AVPacket mPacket = mediaPacket.getAVPacket();
		
		if (mPacket != null) {
			// re-use packet for better timestamp estimation
			av_copy_packet(avPacket, mPacket);
		}
		else {
			ByteBuffer packetData = mediaPacket.getData();
			
			if (packetData != null && packetData.limit() > 0) {
				avPacket.data(new BytePointer(packetData));
			    avPacket.size(packetData.limit());
			}
		}
		
	    // reset frame parameters
		av_frame_unref(avFrame);

	    int len = avcodec_decode_video2(avContext, avFrame, gotFrame, avPacket);
	    
		if (len >= 0 && gotFrame[0] != 0) {
			if (picture == null)
				createImageBuffer();

			long pts = av_frame_get_best_effort_timestamp(avFrame);

			int width = avContext.width();
			int height = avContext.height();
			int channels;
			BytePointer data;

			if (videoResampler == null) {
				if (!srcPictureFormat.isValid())
					srcPictureFormat = new PictureFormat(width, height, PixelFormat.byId(avContext.pix_fmt()));
				if (!dstPictureFormat.isValid())
					dstPictureFormat = new PictureFormat(width, height, pixelFormat);

				videoResampler = new PictureResampler();
				videoResampler.open(srcPictureFormat, dstPictureFormat);
			}

            videoResampler.resample(new AVPicture(avFrame), picture);
            
            channels = picture.linesize(0) / width;
            data = picture.data(0);

			// set buffer parameters to allow correct usage
			data.position(0).capacity(width * height * channels);

			frame = new VideoFrame(data.asBuffer(), width, height, pixelFormat);
			frame.setKeyFrame(avFrame.key_frame() != 0);
			frame.setPts(pts);
			//frame.setStreamIndex(mPacket.stream_index());
		}
		else if ((avPacket.data() == null || (mPacket != null && mPacket.data() == null)) && avPacket.size() == 0) {
			// decoding error or all buffered frames decoded
			frame = null;
        }
	    
	    av_free_packet(avPacket);
	    
		return frame;
	}
	
	private void createImageBuffer() throws JavaFFmpegException {
		int format = pixelFormat.value();
		int width = avContext.width();
		int height = avContext.height();

        picture = new AVPicture();

        if (avpicture_alloc(picture, format, width, height) < 0)
        	throw new JavaFFmpegException("Could not allocate decoding picture.");
	}
	
}
